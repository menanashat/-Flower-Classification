{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab2c00b",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f78552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import scipy.io\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6329cc7",
   "metadata": {},
   "source": [
    "os provides a way to interact with the operating system, such as reading and writing files.\n",
    "\n",
    "random is used to generate random numbers, which can be useful for shuffling indices or selecting random samples from a dataset.\n",
    "\n",
    "scipy.io is used to load the labels from a .mat file.\n",
    "\n",
    "torch is the main PyTorch library and provides many functions and classes for building and training deep learning models.\n",
    "\n",
    "torchvision.transforms provides a set of image transformation functions, such as resizing, cropping, and normalizing the image data.\n",
    "\n",
    "torchvision.models provides pre-trained deep learning models, such as ResNet and VGG.\n",
    "\n",
    "torch.utils.data.Dataset is a PyTorch class that represents a dataset and provides methods for retrieving samples from it.\n",
    "\n",
    "torch.utils.data.DataLoader is a PyTorch class that provides an iterator over a dataset, allowing you to easily iterate over batches of samples\n",
    ".\n",
    "sklearn.metrics provides various performance metrics for classification tasks, such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "PIL.Image is a Python Imaging Library that provides functions for working with images, such as opening, resizing, and saving them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba238b08",
   "metadata": {},
   "source": [
    "# Defining the FlowerDataset class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860dd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, f'image_{idx + 1:05d}.jpg')\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx] - 1  # subtract 1 to make labels 0-indexed\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1efacb",
   "metadata": {},
   "source": [
    "FlowerDataset is a custom PyTorch dataset class that represents the Flower Dataset.\n",
    "\n",
    "__init__ is a method that initializes the dataset by setting the root directory, labels, and an optional transform.\n",
    "\n",
    "__len__ is a method that returns the length of the dataset, which is the number of images.\n",
    "\n",
    "__getitem__ is a method that retrieves a specific sample from the dataset given an index idx. It opens the corresponding image file, applies the specified transform (if any), and returns the image and label.\n",
    "\n",
    "load_flower_data is a function that loads the Flower Dataset and creates a data loader for each split (training, validation, and test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8b7cc",
   "metadata": {},
   "source": [
    "# Defining the load_flower_data function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059a9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flower_data(root_dir, mat_file, train_frac=0.8, random_seed=42):\n",
    "    # Load labels from mat file\n",
    "    labels = scipy.io.loadmat(mat_file)['labels'][0]\n",
    "\n",
    "    # Split images into training and validation sets\n",
    "    num_images = len(labels)\n",
    "    indices = list(range(num_images))\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(indices)\n",
    "    split_idx = int(train_frac * num_images)\n",
    "    train_indices = indices[:split_idx]\n",
    "    val_indices = indices[split_idx:]\n",
    "\n",
    "    # Define transformations to apply to the images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets and data loaders\n",
    "    train_dataset = FlowerDataset(root_dir, labels[train_indices], transform)\n",
    "    val_dataset = FlowerDataset(root_dir, labels[val_indices], transform)\n",
    "    test_dataset = FlowerDataset(root_dir, labels, transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da013e1",
   "metadata": {},
   "source": [
    "load_flower_data is a function that loads the Flower Dataset and creates data loaders for the training, validation, and test sets.\n",
    "\n",
    "root_dir is the directory where the images are stored.\n",
    "\n",
    "mat_file is the .mat file containing the labels for each image.\n",
    "\n",
    "train_frac is the fraction of images to use for training (the rest are split between validation and test).\n",
    "\n",
    "random_seed is the seed for the random number generator used for shuffling the indices.\n",
    "\n",
    "labels are loaded from the .mat file and split into training and validation sets using the specified fraction and random seed.\n",
    "\n",
    "transform is a series of image transformations to apply to the images, including resizing, cropping, converting to a tensor, and normalizing the pixel values.\n",
    "\n",
    "train_dataset, val_dataset, and test_dataset are created using the FlowerDataset class, with the appropriate labels and transformations.\n",
    "\n",
    "train_loader, val_loader, and test_loader are created using the DataLoader class, which provides an iterator over the datasets in batches of the specified size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452dbe8",
   "metadata": {},
   "source": [
    "# Defining the evaluate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709baed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba66f2",
   "metadata": {},
   "source": [
    "evaluate is a function that evaluates the performance of the model on a given data loader.\n",
    "\n",
    "model is the trained deep learning model.\n",
    "\n",
    "loader is the data loader containing the images and labels to evaluate.\n",
    "\n",
    "model.eval() sets the model to evaluation mode, which disables dropout and batch normalization.\n",
    "\n",
    "y_true and y_pred are empty lists that will be filled with the true and predicted labels, respectively.\n",
    "\n",
    "torch.no_grad() disables gradient computation, which speeds up the evaluation and saves memory.\n",
    "\n",
    "For each batch of images and labels in the loader, the images and labels are moved to the device (CPU or GPU), the model is used to predict the labels, and the true and predicted labels are added to the corresponding lists.\n",
    "\n",
    "Several performance metrics are computed using the true and predicted labels, including accuracy, precision, recall, and F1 score.\n",
    "\n",
    "The metrics are returned as a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8cce8",
   "metadata": {},
   "source": [
    "# Setting up the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55e732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff824cbb",
   "metadata": {},
   "source": [
    "device is set to 'cuda' if a CUDA-enabled GPU is available, otherwise it is set to 'cpu'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440159d9",
   "metadata": {},
   "source": [
    "# Loading the Flower Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad898d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'jpg'\n",
    "mat_file = 'imagelabels.mat'\n",
    "num_classes = len(set(scipy.io.loadmat(mat_file)['labels'][0]))\n",
    "train_loader, val_loader, test_loader = load_flower_data(root_dir, mat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13e9f5",
   "metadata": {},
   "source": [
    "The Flower Dataset is loaded using the load_flower_data function, with the root directory 'root_dir' and the .mat file containing the labels 'mat_file'.\n",
    "\n",
    "The training, validation, and test data loaders are returned and assigned to train_loader, val_loader, and test_loader, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4bca5d",
   "metadata": {},
   "source": [
    "# Setting up the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1522a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(2048, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be72196",
   "metadata": {},
   "source": [
    "The model is set up by loading a pre-trained ResNet50 model from models.resnet50(pretrained=True).\n",
    "\n",
    "The model is moved to the device (CPU or GPU) for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a6336",
   "metadata": {},
   "source": [
    "# Defining the loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3bc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df5917",
   "metadata": {},
   "source": [
    "criterion is set to the cross-entropy loss function, which is commonly used for classification tasks.\n",
    "\n",
    "optimizer is set to stochastic gradient descent (SGD) with a learning rate of 0.001 and momentum of 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672bdba",
   "metadata": {},
   "source": [
    "# Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43a10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: train_loss=4.5701, val_acc=0.0159, val_precision=0.0017, val_recall=0.0159, val_f1=0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: train_loss=4.4590, val_acc=0.0256, val_precision=0.0033, val_recall=0.0256, val_f1=0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: train_loss=4.3562, val_acc=0.0232, val_precision=0.0088, val_recall=0.0232, val_f1=0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: train_loss=4.2229, val_acc=0.0232, val_precision=0.0073, val_recall=0.0232, val_f1=0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: train_loss=4.0530, val_acc=0.0134, val_precision=0.0080, val_recall=0.0134, val_f1=0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: train_loss=3.8193, val_acc=0.0122, val_precision=0.0041, val_recall=0.0122, val_f1=0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: train_loss=3.5131, val_acc=0.0159, val_precision=0.0054, val_recall=0.0159, val_f1=0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: train_loss=3.1509, val_acc=0.0098, val_precision=0.0066, val_recall=0.0098, val_f1=0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: train_loss=2.7467, val_acc=0.0140, val_precision=0.0115, val_recall=0.0140, val_f1=0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: train_loss=2.3127, val_acc=0.0128, val_precision=0.0074, val_recall=0.0128, val_f1=0.0081\n",
      "Test Accuracy: 0.0151, Test Precision: 0.0123, Test Recall: 0.0151,Test F1 Score: 0.0119\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        target = labels.type(torch.int64)  # Convert target tensor to int64\n",
    "        loss = criterion(outputs, target)  # Use the updated target tensor\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    val_acc, val_precision, val_recall, val_f1 = evaluate(model, val_loader)\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}/{num_epochs}: train_loss={train_loss:.4f}, val_acc={val_acc:.4f}, val_precision={val_precision:.4f}, val_recall={val_recall:.4f}, val_f1={val_f1:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_acc, test_precision, test_recall, test_f1 = evaluate(model, test_loader)\n",
    "print(\n",
    "    f'Test Accuracy: {test_acc:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f},Test F1 Score: {test_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a08f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
